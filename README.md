# Coding-Assignment-Data-Curation-and-Analysis

# Project Goal:
#   The goal of this project is to scrape GDP (Gross Domestic Product) data from a Wikipedia page and visualize it using Python. The project involves web scraping using the requests and BeautifulSoup libraries to extract data and then visualizing this data using the pandas, Matplotlib, and Seaborn libraries.

# Source Data/API Documentation:
#   We obtained the GDP data from the Wikipedia page "List of countries by GDP (nominal)" (https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)). The data on this Wikipedia page is publicly available and does not require a specific API.

# Data Licence:
#   The data scraped from the Wikipedia page is subject to Wikipedia's terms of use and license. Be sure to review and comply with these terms before using the data.

# Data Attributes/Descriptions:
#   Country/Territory: The name of the country or territory.
#   IMF Forecast: GDP values as forecasted by the International Monetary Fund.
#   IMF Year: The year to which the IMF forecast corresponds.
#   World Bank Estimate: GDP values estimated by the World Bank.
#   World Bank Year: The year to which the World Bank estimate corresponds.
#   United Nations Estimate: GDP values estimated by the United Nations.
#   United Nations Year: The year to which the United Nations estimate corresponds.

# Data Visualization:
#   Top N Countries by GDP (IMF Forecast): A bar plot that shows the top N countries by GDP as forecasted by the IMF.
#   GDP by UN Region: A bar plot displaying the total GDP for each UN region, sorted in descending order.
#   GDP Estimates Over Time for Selected Countries: Line plots showing the GDP estimates over time for selected countries, including IMF forecasts, World Bank estimates, and United Nations estimates.
#   GDP Trends Over the Years: A line plot illustrating the mean GDP trends over the years for IMF, World Bank, and United Nations estimates.

# Known/Potential Issues:
#   Wikipedia data may be edited by multiple contributors, which can introduce bias or errors in the data. It's important to validate and cross-reference the information obtained from Wikipedia with other sources if high accuracy is required.

# Dependencies:
#   To run this project, you will need the following Python libraries:
#     requests
#     BeautifulSoup
#     pandas
#     re
#     matplotlib
#     seaborn
#   You can install these libraries using pip install.

	
	
	
	
	
	


